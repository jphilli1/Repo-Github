{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMzL8Bq18AT+BfbgX0baH+i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jphilli1/Repo-Github/blob/main/Work/CFA%20L2%20Project/Financial_Forecasting_ML_L2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqz5BVCNxdqB"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Set working directory to script's location\n",
        "script_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "os.chdir(script_dir)\n",
        "print(f\"Current working directory set to: {os.getcwd()}\")\n",
        "print(f\"Files in current directory: {os.listdir()}\")\n",
        "cmd_path = os.path.join(os.path.dirname(__file__), \"setup_env.cmd\")\n",
        "subprocess.call(cmd_path, shell=True)\n",
        "\n",
        "\n",
        "\n",
        "# --- Imports after environment setup ---\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import sys\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', 250)\n",
        "\n",
        "\n",
        "# Load the financial data\n",
        "try:\n",
        "    df = pd.read_csv('financial_data.csv')\n",
        "    print(\"financial_data.csv loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'financial_data.csv' not found. Please ensure it's in the same directory as the script.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# --- Filter DataFrame for Apple data (existing task) ---\n",
        "apple_df = df[df['Ticker'] == 'AAPL'].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "\n",
        "REVENUE_COLUMN = 'Revenue'\n",
        "DATE_COLUMN = 'Report Date'\n",
        "\n",
        "if REVENUE_COLUMN in apple_df.columns and DATE_COLUMN in apple_df.columns:\n",
        "    if not apple_df.empty:\n",
        "        apple_df[REVENUE_COLUMN] = pd.to_numeric(apple_df[REVENUE_COLUMN], errors='coerce')\n",
        "        apple_df.dropna(subset=[REVENUE_COLUMN], inplace=True)\n",
        "\n",
        "        if not apple_df.empty:\n",
        "            max_revenue_row = apple_df.loc[apple_df[REVENUE_COLUMN].idxmax()]\n",
        "            max_quarterly_revenue = max_revenue_row[REVENUE_COLUMN]\n",
        "            max_revenue_date = max_revenue_row[DATE_COLUMN]\n",
        "            print(f\"Maximum Quarterly Revenue for Apple: ${max_quarterly_revenue:,.2f}\")\n",
        "            print(f\"Corresponding Date: {max_revenue_date}\")\n",
        "        else:\n",
        "            print(\"No valid Apple (AAPL) revenue data found after cleaning.\")\n",
        "    else:\n",
        "        print(\"No Apple (AAPL) data found in the DataFrame after filtering.\")\n",
        "else:\n",
        "    print(f\"Required columns ('{REVENUE_COLUMN}' or '{DATE_COLUMN}') not found in the DataFrame for Apple. Available columns are: {apple_df.columns.tolist()}\")\n",
        "\n",
        "# Drop the \"% Change in Quarterly Revenue (Target Output)\" column from apple_df\n",
        "# Check if the column exists before dropping to prevent errors\n",
        "target_revenue_col = '% Change in Quarterly Revenue (Target Output)'\n",
        "if target_revenue_col in apple_df.columns:\n",
        "    apple_df = apple_df.drop(columns = target_revenue_col)\n",
        "    print(f\"'{target_revenue_col}' dropped from Apple DataFrame.\")\n",
        "else:\n",
        "    print(f\"'{target_revenue_col}' not found in Apple DataFrame, skipping drop.\")\n",
        "'''\n",
        "PRACTICE OPPORTUNITY:\n",
        "\n",
        "Write a Python code that performs the following tasks:\n",
        "Filter out the Pandas DataFrame df to only contain rows pertaining to Nvidia corporation (Ticker Symbol: NVDA)\n",
        "Display the histogram for the output column \"% Change in Quarterly EPS (Target Output)\" for Nvidia corporation using 100 bins\n",
        "'''\n",
        "# --- Filter DataFrame for Nvidia data (NEW TASK) ---\n",
        "nvidia_df = df[df['Ticker'] == 'NVDA'].copy() # Use .copy() for the new DataFrame\n",
        "\n",
        "# --- Display histogram for Nvidia's \"% Change in Quarterly EPS (Target Output)\" ---\n",
        "eps_target_column = '% Change in Quarterly EPS (Target Output)'\n",
        "\n",
        "if eps_target_column in nvidia_df.columns:\n",
        "    if not nvidia_df.empty:\n",
        "        # Convert the EPS column to numeric, handling potential non-numeric values\n",
        "        nvidia_df[eps_target_column] = pd.to_numeric(nvidia_df[eps_target_column], errors='coerce')\n",
        "        nvidia_df.dropna(subset=[eps_target_column], inplace=True)\n",
        "\n",
        "        if not nvidia_df.empty:\n",
        "            print(f\"\\nDisplaying histogram for Nvidia's '{eps_target_column}':\")\n",
        "            # Multiply by 100 to display as percentage if not already in percentage form\n",
        "            fig = px.histogram(nvidia_df[eps_target_column] * 100, nbins=100,\n",
        "                               title=f'Histogram of {eps_target_column} for Nvidia (NVDA)',\n",
        "                               labels={'value': 'EPS Change (%)', 'count': 'Frequency'})\n",
        "            fig.update_layout({'plot_bgcolor': \"white\"})\n",
        "            fig.show() # Display the plot\n",
        "        else:\n",
        "            print(f\"No valid data found in '{eps_target_column}' for Nvidia after cleaning.\")\n",
        "    else:\n",
        "        print(\"No Nvidia (NVDA) data found in the DataFrame after filtering.\")\n",
        "else:\n",
        "    print(f\"'{eps_target_column}' not found in Nvidia DataFrame. Available columns are: {nvidia_df.columns.tolist()}\")\n",
        "\n",
        "# --- Remaining original correlation analysis (for Apple_df) ---\n",
        "print(\"\\nProceeding with correlation analysis for Apple data:\")\n",
        "target_eps_col = '% Change in Quarterly EPS (Target Output)'\n",
        "if target_eps_col in apple_df.columns:\n",
        "    correlation_matrix = apple_df.corr(numeric_only=True) # Ensure only numeric columns are used for correlation\n",
        "\n",
        "    print(\"\\nCorrelation matrix for Apple (Full):\")\n",
        "    print(correlation_matrix)\n",
        "\n",
        "    print(f\"\\nCorrelation coefficients with '{target_eps_col}' for Apple:\")\n",
        "    print(correlation_matrix[[target_eps_col]])\n",
        "\n",
        "    # Let's sort the correlation values in a descending order\n",
        "    # Ensure the target column itself is not included in 'top_positive_corr' if it's perfectly 1\n",
        "    # Drop rows where target column is correlated with itself (value is 1.0)\n",
        "    sorted_corr = correlation_matrix[[target_eps_col]].sort_values(\n",
        "        target_eps_col, ascending=False\n",
        "    ).drop(labels=[target_eps_col], errors='ignore')\n",
        "\n",
        "\n",
        "    # Let's display the top 10 positively correlated features with the output (target column)\n",
        "    top_positive_corr = sorted_corr.head(10)\n",
        "    print(\"\\nTop 10 Positively Correlated Features with EPS Change (Apple):\")\n",
        "    print(top_positive_corr)\n",
        "\n",
        "    # Let's obtain the top 10 negatively correlated features with the output (target column)\n",
        "    top_negative_corr = correlation_matrix[[target_eps_col]].sort_values(target_eps_col).head(10)\n",
        "    # Remove the target column itself if it's in the negative list due to 0/NaN values etc.\n",
        "    top_negative_corr = top_negative_corr.drop(labels=[target_eps_col], errors='ignore')\n",
        "    print(\"\\nTop 10 Negatively Correlated Features with EPS Change (Apple):\")\n",
        "    print(top_negative_corr)\n",
        "\n",
        "\n",
        "    # Let's display the top positively and negatively correlated features with the output\n",
        "    # Ensure 'index' is accessed correctly from the reset_index() call\n",
        "    selected_columns = []\n",
        "    if not top_negative_corr.empty:\n",
        "        selected_columns.extend(top_negative_corr.index.tolist()) # Use .index to get column names directly\n",
        "    if not top_positive_corr.empty:\n",
        "        selected_columns.extend(top_positive_corr.index.tolist())\n",
        "\n",
        "    # Add the target EPS column to the selected columns if it's not already there for viewing\n",
        "    if target_eps_col not in selected_columns:\n",
        "        selected_columns.append(target_eps_col)\n",
        "\n",
        "    # Filter apple_df to only include the selected columns\n",
        "    filtered_apple_df_for_display = apple_df[selected_columns]\n",
        "    print(\"\\nApple DataFrame with Top Positively and Negatively Correlated Features:\")\n",
        "    print(filtered_apple_df_for_display.head())\n",
        "\n",
        "\n",
        "    # Let's re-calculate the correlation matrix to only calculate the top 10 positively and negatively correlated features\n",
        "    # Filter the DataFrame to include only these specific columns for the final heatmap\n",
        "    filtered_corr_df = apple_df[selected_columns]\n",
        "    correlation_matrix_filtered = filtered_corr_df.corr(numeric_only=True)\n",
        "    print(\"\\nRecalculated Correlation Matrix for Top Features (Apple):\")\n",
        "    print(correlation_matrix_filtered)\n",
        "\n",
        "    # Let's use Seaborn to display a heatmap for the correlation matrix\n",
        "    f, ax = plt.subplots(figsize = (15, 9))\n",
        "    sns.heatmap(correlation_matrix_filtered, annot = True, cmap='coolwarm', fmt=\".2f\")\n",
        "    plt.title('Heatmap of Top Correlated Features for Apple EPS Change')\n",
        "    plt.show() # Display the plot\n",
        "else:\n",
        "    print(f\"Target column '{target_eps_col}' not found in Apple DataFrame for correlation analysis.\")\n",
        "apple_df['Publish Date'] = pd.to_datetime(apple_df['Publish Date'])\n",
        "# Sorting the DataFrame in an ascending order based on the \"Publish Date\" column\n",
        "apple_df.sort_values(by = 'Publish Date', ascending = True, inplace = True)\n",
        "apple_df\n",
        "# Let's drop the following columns from the Pandas DataFrame\n",
        "cols_to_drop = ['Ticker','Sector', 'Industry','Company Name', 'Report Date', 'Currency',\n",
        "                'Fiscal Year', 'Publish Date', 'Restated Date']\n",
        "\n",
        "apple_df = apple_df.drop(columns = cols_to_drop)\n",
        "apple_df\n",
        "# Let's display the original \"Fiscal Period\" column\n",
        "print(apple_df['Fiscal Period'])\n",
        "\n",
        "# Let's display the one-hot encoded version of the \"Fiscal Period\" column\n",
        "fiscal_encoded = pd.get_dummies(apple_df['Fiscal Period'])\n",
        "fiscal_encoded\n",
        "# Drop the 'Fiscal Period' column from the Pandas DataFrame\n",
        "apple_df = apple_df.drop('Fiscal Period', axis = 1)\n",
        "\n",
        "# Concatenate the original DataFrame and the one-hot encoded \"Fiscal Period\" column\n",
        "apple_df = pd.concat([apple_df, fiscal_encoded], axis = 1)\n",
        "apple_df\n",
        "\n",
        "'''\n",
        "PRACTICE OPPORTUNITY:\n",
        "\n",
        "Write a Python code that performs the following tasks:\n",
        "Read the \"financial_data.csv\" file using Pandas and place the result in a Pandas DataFrame titled \"df\"\n",
        "Filter \"df\" Pandas DataFrame to only include General Electric data (Ticker Symbol: GE), and place the results in a Pandas DataFrame titled \"general_electric_df\"\n",
        "Perform one-hot encoding to the \"Fiscal Period\" column in \"general_electric_df\" DataFrame using Pandas pd.get_dummies() function\n",
        "Drop the \"Fiscal Period\" column from \"general_electric_df\" DataFrame and concatenate the one-hot encoded data\n",
        "'''\n",
        "# --- Filter DataFrame for General Electric data (NEW TASK) ---\n",
        "general_electric_df = df[df['Ticker'] == 'GE'].copy() # Filter for GE and create a copy\n",
        "\n",
        "print(\"\\nGeneral Electric DataFrame created.\")\n",
        "# print(general_electric_df.head()) # Uncomment to verify\n",
        "\n",
        "# --- Perform one-hot encoding on 'Fiscal Period' column ---\n",
        "FISCAL_PERIOD_COLUMN = 'Fiscal Period'\n",
        "\n",
        "if FISCAL_PERIOD_COLUMN in general_electric_df.columns:\n",
        "    # Create one-hot encoded columns\n",
        "    one_hot_encoded_periods = pd.get_dummies(general_electric_df[FISCAL_PERIOD_COLUMN], prefix=FISCAL_PERIOD_COLUMN)\n",
        "    print(f\"One-hot encoding performed on '{FISCAL_PERIOD_COLUMN}'.\")\n",
        "\n",
        "    # Drop the original 'Fiscal Period' column and concatenate the one-hot encoded data\n",
        "    general_electric_df = pd.concat(\n",
        "        [general_electric_df.drop(columns=[FISCAL_PERIOD_COLUMN]), one_hot_encoded_periods],\n",
        "        axis=1\n",
        "    )\n",
        "    print(f\"Original '{FISCAL_PERIOD_COLUMN}' column dropped and one-hot encoded columns concatenated.\")\n",
        "    # print(general_electric_df.head()) # Uncomment to verify the new DataFrame structure\n",
        "else:\n",
        "    print(f\"'{FISCAL_PERIOD_COLUMN}' column not found in General Electric DataFrame. Skipping one-hot encoding.\")\n",
        "'''\n",
        "PRACTICE OPPORTUNITY:\n",
        "\n",
        "Using Scikit-Learn library, split the data into 30% for testing and 70% for training\n",
        "Perform a sanity check by obtaining the shape of the training and testing datasets\n",
        "Enable shuffling and rerun the code. Comment on your results.\n",
        "'''\n",
        "#%%\n",
        "# --- Prepare data for General Electric ---\n",
        "# Ensure general_electric_df exists and has been processed (one-hot encoded) from previous steps\n",
        "# If general_electric_df is not available from previous runs, you would need to re-run the prior cell.\n",
        "# Assuming 'general_electric_df' is already created and one-hot encoded from the previous step.\n",
        "\n",
        "TARGET_OUTPUT_COLUMN = '% Change in Quarterly EPS (Target Output)'\n",
        "\n",
        "# Drop the target output column to create the input features (X_ge)\n",
        "# Create a list of columns to drop for X_ge\n",
        "columns_to_drop_X = [TARGET_OUTPUT_COLUMN, 'Company Name', 'Sector', 'Industry', 'Ticker', 'Report Date', 'Currency', 'Publish Date', 'Restated Date']\n",
        "# Filter out columns that do not exist in the DataFrame\n",
        "existing_columns_to_drop_X = [col for col in columns_to_drop_X if col in general_electric_df.columns]\n",
        "\n",
        "\n",
        "# Separate features (X_ge) and target (y_ge)\n",
        "X_ge = general_electric_df.drop(columns=existing_columns_to_drop_X, axis=1).copy()\n",
        "y_ge = general_electric_df[TARGET_OUTPUT_COLUMN].copy()\n",
        "\n",
        "# Convert all columns in X_ge to numeric, coercing errors to NaN\n",
        "# This is crucial for machine learning models and train_test_split if non-numeric data remains\n",
        "for col in X_ge.columns:\n",
        "    X_ge[col] = pd.to_numeric(X_ge[col], errors='coerce')\n",
        "\n",
        "# Handle NaNs in X_ge (e.g., fill with 0 or mean, or drop rows)\n",
        "# For simplicity, we'll fill NaN with 0 for now. Consider more sophisticated imputation methods for real projects.\n",
        "X_ge.fillna(0, inplace=True)\n",
        "\n",
        "# Ensure y_ge is also numeric and handle potential NaNs\n",
        "y_ge = pd.to_numeric(y_ge, errors='coerce')\n",
        "y_ge.fillna(0, inplace=True) # Fill NaNs in target with 0 or a suitable value\n",
        "\n",
        "\n",
        "print(\"\\n--- General Electric Data Preparation ---\")\n",
        "print(\"Input features (X_ge) head:\")\n",
        "print(X_ge.head())\n",
        "print(\"\\nOutput target (y_ge) head:\")\n",
        "print(y_ge.head())\n",
        "\n",
        "\n",
        "# --- Perform data train/test split with shuffling enabled ---\n",
        "# Test size 30% (0.3), training size 70%\n",
        "# shuffle = True: Data points are randomly reordered before splitting.\n",
        "# This helps ensure that both training and testing sets are representative of the overall dataset\n",
        "# and prevents any ordering bias (e.g., if data is sorted by date or value).\n",
        "X_train_ge, X_test_ge, y_train_ge, y_test_ge = train_test_split(X_ge, y_ge, test_size=0.3, shuffle=True, random_state=42) # random_state for reproducibility\n",
        "\n",
        "# --- Sanity check: Obtain the shape of the training and testing datasets ---\n",
        "print(\"\\n--- Sanity Check for GE Data Split ---\")\n",
        "print(f\"Shape of X_train_ge: {X_train_ge.shape}\")\n",
        "print(f\"Shape of X_test_ge: {X_test_ge.shape}\")\n",
        "print(f\"Shape of y_train_ge: {y_train_ge.shape}\")\n",
        "print(f\"Shape of y_test_ge: {y_test_ge.shape}\")\n",
        "\n",
        "print(\"\\n--- Display Training Set (Shuffled) ---\")\n",
        "print(\"Note: Data points are randomly ordered in the training set due to 'shuffle = True'.\")\n",
        "print(X_train_ge.head())\n",
        "'''\n",
        "PRACTICE OPPORTUNITY:\n",
        "\n",
        "Set the fit_intercept attribute to False, retrain the multiple linear regression model and evaluate its performance\n",
        "Display the estimated coefficients and Y-intercept. What do you conclude?\n",
        "'''\n",
        "\n",
        "print(\"--- Training Linear Regression Model without Intercept ---\")\n",
        "\n",
        "linear_regression_model_no_intercept = linear_model.LinearRegression(fit_intercept=False)\n",
        "linear_regression_model_no_intercept.fit(X_train_ge, y_train_ge) # Corrected to use GE data variables\n",
        "\n",
        "y_predict_no_intercept = linear_regression_model_no_intercept.predict(X_test_ge) # Corrected\n",
        "\n",
        "RMSE_no_intercept = float(np.sqrt(mean_squared_error(y_test_ge, y_predict_no_intercept))) # Corrected\n",
        "MSE_no_intercept = mean_squared_error(y_test_ge, y_predict_no_intercept) # Corrected\n",
        "MAE_no_intercept = mean_absolute_error(y_test_ge, y_predict_no_intercept) # Corrected\n",
        "\n",
        "print('\\nPerformance Metrics (fit_intercept=False):')\n",
        "print('Root Mean Squared Error (RMSE) =', RMSE_no_intercept)\n",
        "print('Mean Squared Error (MSE) =', MSE_no_intercept)\n",
        "print('Mean Absolute Error (MAE) =', MAE_no_intercept)\n",
        "\n",
        "plt.figure(figsize = (13, 8))\n",
        "plt.plot(y_predict_no_intercept, y_test_ge, 'o', color = 'b', markersize = 10, label='Predictions vs Actuals (No Intercept)') # Corrected\n",
        "plt.xlabel('Model Predictions')\n",
        "plt.ylabel('Actual Values (Ground Truth)')\n",
        "plt.title('Model Predictions Vs. Actual Values (Ground Truth) - No Intercept')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print('\\n--- Model Parameters (fit_intercept=False) ---')\n",
        "print('Trained Model Y-intercept:', linear_regression_model_no_intercept.intercept_)\n",
        "print('Estimated Coefficients:', linear_regression_model_no_intercept.coef_)\n",
        "\n",
        "\n",
        "# --- TRAIN AND EVALUATE A RANDOM FOREST ALGORITHM (FIXED) ---\n",
        "print(\"\\n--- Training Random Forest Regression Model (Initial) ---\")\n",
        "\n",
        "random_forest_model = RandomForestRegressor(n_estimators = 5, max_depth = 10, random_state=42) # Added random_state\n",
        "random_forest_model.fit(X_train_ge, y_train_ge) # CORRECTED: Use GE data variables\n",
        "\n",
        "y_predict = random_forest_model.predict(X_test_ge) # CORRECTED: Use GE data variables\n",
        "\n",
        "RMSE = float(np.sqrt(mean_squared_error(y_test_ge, y_predict))) # CORRECTED\n",
        "MSE = mean_squared_error(y_test_ge, y_predict) # CORRECTED\n",
        "MAE = mean_absolute_error(y_test_ge, y_predict) # CORRECTED\n",
        "\n",
        "print('\\nPerformance Metrics (Random Forest, n_estimators=5, max_depth=10):')\n",
        "print('Root Mean Squared Error (RMSE) =', RMSE)\n",
        "print('Mean Squared Error (MSE) =', MSE)\n",
        "print('Mean Absolute Error (MAE) =', MAE)\n",
        "\n",
        "plt.figure(figsize = (13, 8))\n",
        "plt.plot(y_predict, y_test_ge, 'o', color = 'r', markersize = 10) # CORRECTED\n",
        "plt.xlabel('Model Predictions')\n",
        "plt.ylabel('Actual Values (Ground Truth)')\n",
        "plt.title('Random Forest Model Predictions Vs. Actual Values (Ground Truth)');\n",
        "plt.grid(True, linestyle='--', alpha=0.6) # Added grid\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "PRACTICE OPPORTUNITY:\n",
        "\n",
        "Increase the maximum depth of the tree by setting max_depth = 100\n",
        "Retrain the Random Forest Regression model and evaluate its performance\n",
        "'''\n",
        "\n",
        "# --- PRACTICE OPPORTUNITY: Random Forest with max_depth = 100 (FIXED) ---\n",
        "print(\"\\n--- Training Random Forest Regression Model with max_depth = 100 ---\")\n",
        "\n",
        "random_forest_model_100 = RandomForestRegressor(max_depth=100, random_state=42)\n",
        "random_forest_model_100.fit(X_train_ge, y_train_ge)\n",
        "\n",
        "y_predict_rf_100 = random_forest_model_100.predict(X_test_ge)\n",
        "\n",
        "RMSE_rf_100 = float(np.sqrt(mean_squared_error(y_test_ge, y_predict_rf_100)))\n",
        "MSE_rf_100 = mean_squared_error(y_test_ge, y_predict_rf_100)\n",
        "MAE_rf_100 = mean_absolute_error(y_test_ge, y_predict_rf_100)\n",
        "\n",
        "print('\\nPerformance Metrics (Random Forest, max_depth=100):')\n",
        "print('Root Mean Squared Error (RMSE) =', RMSE_rf_100)\n",
        "print('Mean Squared Error (MSE) =', MSE_rf_100)\n",
        "print('Mean Absolute Error (MAE) =', MAE_rf_100)\n",
        "\n",
        "plt.figure(figsize = (13, 8))\n",
        "plt.plot(y_predict_rf_100, y_test_ge, 'o', color = 'g', markersize = 10, label='Predictions vs Actuals (RF max_depth=100)')\n",
        "plt.xlabel('Model Predictions')\n",
        "plt.ylabel('Actual Values (Ground Truth)')\n",
        "plt.title('Random Forest Model Predictions Vs. Actual Values (Ground Truth) - Max Depth 100')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "'''\n",
        "TRAIN AND EVALUATE AN ARTIFICIAL NEURAL NETWORK TO SOLVE REGRESSION PROBLEMS\n",
        "PRACTICE OPPORTUNITY:\n",
        "\n",
        "Change the architecture of the existing Artificial Neural Network model by introducing an additional dense layer with Dropout. Feel free to choose the number of neurons.\n",
        "Print the model summary and list the number of trainable parameters\n",
        "'''\n",
        "# Data scaling using MinMaxScaler()\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_X.fit(X_train_ge)\n",
        "X_train_scaled = scaler_X.transform(X_train_ge)\n",
        "X_test_scaled = scaler_X.transform(X_test_ge)\n",
        "\n",
        "scaler_y = MinMaxScaler()\n",
        "scaler_y.fit(pd.DataFrame(y_train_ge))\n",
        "y_train_scaled = scaler_y.transform(pd.DataFrame(y_train_ge))\n",
        "y_test_scaled = scaler_y.transform(pd.DataFrame(y_test_ge))\n",
        "\n",
        "# Building the original ANN model usingimport tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Normalization, Dropout\n",
        "print(\"\\n--- Original ANN Model Summary ---\")\n",
        "ANN_model = Sequential()\n",
        "ANN_model.add(Normalization(input_shape = [X_train_ge.shape[1],], axis = None))\n",
        "ANN_model.add(Dense(1024, activation = 'relu'))\n",
        "ANN_model.add(Dropout(0.3))\n",
        "ANN_model.add(Dense(512, activation = 'relu'))\n",
        "ANN_model.add(Dropout(0.3))\n",
        "ANN_model.add(Dense(256, activation = 'sigmoid'))\n",
        "ANN_model.add(Dropout(0.3))\n",
        "ANN_model.add(Dense(32, activation = 'sigmoid'))\n",
        "ANN_model.add(Dropout(0.3))\n",
        "ANN_model.add(Dense(units = 1, activation = 'linear'))\n",
        "ANN_model.summary()\n",
        "\n",
        "# Compile the model\n",
        "ANN_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001), loss = 'mean_squared_error')\n",
        "\n",
        "# Fit the model\n",
        "print(\"Training original ANN model for 500 epochs...\")\n",
        "history = ANN_model.fit(X_train_scaled, y_train_scaled, epochs = 500, verbose=0)\n",
        "\n",
        "# Generate model predictions and scale back\n",
        "y_predict_scaled = ANN_model.predict(X_test_scaled)\n",
        "y_predict_original = scaler_y.inverse_transform(y_predict_scaled)\n",
        "y_test_original_ann = scaler_y.inverse_transform(y_test_scaled)\n",
        "\n",
        "# Generate regression metrics\n",
        "RMSE_original = float(np.sqrt(mean_squared_error(y_test_original_ann, y_predict_original)))\n",
        "MSE_original = mean_squared_error(y_test_original_ann, y_predict_original)\n",
        "MAE_original = mean_absolute_error(y_test_original_ann, y_predict_original)\n",
        "\n",
        "print('\\nPerformance Metrics (Original ANN Model):')\n",
        "print('Root Mean Squared Error (RMSE) =', RMSE_original)\n",
        "print('Mean Squared Error (MSE) =', MSE_original)\n",
        "print('Mean Absolute Error (MAE) =', MAE_original)\n",
        "\n",
        "# Plot model predictions\n",
        "plt.figure(figsize = (13, 8))\n",
        "plt.plot(y_predict_original, y_test_original_ann, 'o', color = 'r', markersize = 10)\n",
        "plt.xlabel('Model Predictions')\n",
        "plt.ylabel('Actual Values (Ground Truth)')\n",
        "plt.title('Original ANN Model Predictions Vs. Actual Values (Ground Truth)');\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --- PRACTICE OPPORTUNITY: Modified ANN Architecture ---\n",
        "print(\"\\n--- Modified ANN Model Summary ---\")\n",
        "\n",
        "ANN_model_modified = Sequential()\n",
        "ANN_model_modified.add(Normalization(input_shape = [X_train_ge.shape[1],], axis = None))\n",
        "ANN_model_modified.add(Dense(1024, activation = 'relu'))\n",
        "ANN_model_modified.add(Dropout(0.3))\n",
        "ANN_model_modified.add(Dense(512, activation = 'relu'))\n",
        "ANN_model_modified.add(Dropout(0.3))\n",
        "# New Dense Layer with Dropout\n",
        "ANN_model_modified.add(Dense(128, activation = 'relu'))\n",
        "ANN_model_modified.add(Dropout(0.3))\n",
        "ANN_model_modified.add(Dense(256, activation = 'sigmoid'))\n",
        "ANN_model_modified.add(Dropout(0.3))\n",
        "ANN_model_modified.add(Dense(32, activation = 'sigmoid'))\n",
        "ANN_model_modified.add(Dropout(0.3))\n",
        "ANN_model_modified.add(Dense(units = 1, activation = 'linear'))\n",
        "\n",
        "ANN_model_modified.summary()\n",
        "\n",
        "print(\"\\n--- Compiling and Training Modified ANN Model ---\")\n",
        "ANN_model_modified.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001), loss = 'mean_squared_error')\n",
        "\n",
        "print(\"Training modified model for 500 epochs...\")\n",
        "history_modified = ANN_model_modified.fit(X_train_scaled, y_train_scaled, epochs = 500, verbose=0)\n",
        "\n",
        "y_predict_scaled_modified = ANN_model_modified.predict(X_test_scaled)\n",
        "y_predict_modified = scaler_y.inverse_transform(y_predict_scaled_modified)\n",
        "y_test_original_modified_ann = scaler_y.inverse_transform(y_test_scaled)\n",
        "\n",
        "RMSE_modified = float(np.sqrt(mean_squared_error(y_test_original_modified_ann, y_predict_modified)))\n",
        "MSE_modified = mean_squared_error(y_test_original_modified_ann, y_predict_modified)\n",
        "MAE_modified = mean_absolute_error(y_test_original_modified_ann, y_predict_modified)\n",
        "\n",
        "print('\\nPerformance Metrics (Modified ANN Model):')\n",
        "print('Root Mean Squared Error (RMSE) =', RMSE_modified)\n",
        "print('Mean Squared Error (MSE) =', MSE_modified)\n",
        "print('Mean Absolute Error (MAE) =', MAE_modified)\n",
        "\n",
        "plt.figure(figsize = (13, 8))\n",
        "plt.plot(y_predict_modified, y_test_original_modified_ann, 'o', color = 'purple', markersize = 10)\n",
        "plt.xlabel('Model Predictions')\n",
        "plt.ylabel('Actual Values (Ground Truth)')\n",
        "plt.title('Modified ANN Model Predictions Vs. Actual Values (Ground Truth)');\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()"
      ]
    }
  ]
}